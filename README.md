<!-- Portada -->
<p align="center">
  <p align="center">
    <img src="img/portadaA4.png"         alt="Portada A4"            width="1200"/>
  </p>
</p>

<!-- Badges -->
<p align="center">
  <a href="https://github.com/mamanirafa/Testing/actions">
    <img src="https://img.shields.io/github/actions/workflow/status/mamanirafa/Testing/ci.yml" alt="Build Status"/>
  </a>
  <a href="LICENSE">
    <img src="https://img.shields.io/github/license/mamanirafa/Testing" alt="License"/>
  </a>
</p>

---
---

**Carrera:** Tecnicatura Superior en Ciencia de Datos e Inteligencia Artificial  
**InstituciÃ³n:** PolitÃ©cnico Malvinas Argentinas  
**Materia:** Aprendizaje AutomÃ¡tico

**Proyecto:** PredicciÃ³n del volumen sostenible de captura de Centolla en Tierra del Fuego

- **Alumno:** MAMANI, Rafael
- **Profesor:** MartÃ­n Mirabete

---
##  Indice
### Accesos rÃ¡pidos:
- [Resumen](#resumen)
- [Objetivo General](#objetivo-general)
- [Objetivos EspecÃ­ficos](#objetivos-especÃ­ficos)
- [Contexto y Relevancia](#contexto-y-relevancia)
- [Origen y DescripciÃ³n de los Datos](#origen-y-descripciÃ³n-de-los-datos)
- [Estructura del Repositorio](#estructura-del-repositorio)
- [Licencia](#licencia)
---
PredicciÃ³n de ProducciÃ³n Sostenible de Trucha en TDF mediante Modelos de Aprendizaje AutomÃ¡tico
==============================
# DescripciÃ³n del Proyecto
##  Resumen

Este proyecto de aprendizaje automÃ¡tico busca predecir el volumen sostenible de capturas de centolla (Lithodes
santolla) por aÃ±o en Tierra del Fuego, utilizando un modelo de regresiÃ³n implementado en Python con scikitlearn. El dataset principal, â€œPesca y Puertos Pesquerosâ€ del Ministerio de EconomÃ­a, contiene datos histÃ³ricos
que permiten identificar patrones para la predicciÃ³n. El proyecto utiliza la plantilla Cookiecutter Data Science y
un repositorio Git para garantizar reproducibilidad, con resultados documentados. El
modelo no realiza un anÃ¡lisis estadÃ­stico, sino que aprende patrones de los datos para generar predicciones
Ãºtiles para simulaciones y toma de decisiones en la gestiÃ³n pesquera.

---

##  Objetivo General
Desarrollar un modelo de regresiÃ³n que prediga el volumen sostenible de capturas de centolla (en toneladas)
por aÃ±o en Tierra del Fuego, basado en variables como esfuerzo pesquero, condiciones ambientales y
regulaciones, para apoyar la gestiÃ³n pesquera sostenible.

![Ejemplo de uso](img/objetivofin.png)

---

##  Objetivos EspecÃ­ficos
1. Preprocesar el dataset para filtrar datos de Tierra del Fuego y centolla, asegurando patrones claros para
el aprendizaje del modelo.
2. Implementar un modelo de regresiÃ³n (Random Forest Regressor o Linear Regression) para predecir el
volumen sostenible.
3. Modelo con mÃ©tricas como MSE, MAE y RÂ², validando su capacidad para aprender patrones predictivos.
4. Generar simulaciones de volÃºmenes sostenibles para recomendar cuotas de pesca optimizadas.

---

##  Contexto y Relevancia
Tierra del Fuego,depende de la pesca de centolla como pilar econÃ³mico en puertos como Ushuaia y RÃ­o Grande.
La sobreexplotaciÃ³n y el cambio climÃ¡tico amenazan este recurso, mientras que el aislamiento geogrÃ¡fico
complica la logÃ­stica. La certificaciÃ³n MSC de la pesquerÃ­a de centolla resalta la importancia de la sostenibilidad
por lo que predecir volÃºmenes sostenibles es relevante para: (1) proteger la biodiversidad marina, (2) sostener
la economÃ­a local, (3) informar cuotas de pesca, y (4) adaptarse a cambios ambientales. La originalidad radica
en aplicar regresiÃ³n a datos especÃ­ficos de centolla en una regiÃ³n remota, generando simulaciones prÃ¡cticas.

---

##  Origen y DescripciÃ³n de los datos

### Origen del Dataset

*   **Instituto Nacional de EstadÃ­sticas (INE) Chile**, Global Fishing Watch, y fuentes oficiales de regulaciÃ³n pesquera.
*   **Fecha de AdquisiciÃ³n:** Junio de 2025.
*   **RecopilaciÃ³n:** Datos recolectados y consolidados a partir de informes oficiales de desembarques, registros satelitales de esfuerzo pesquero, datos oceanogrÃ¡ficos y normativas vigentes.
*   **PolÃ­tica de Datos:** InformaciÃ³n pÃºblica y gratuita, sujeta a procesos de validaciÃ³n y depuraciÃ³n para garantizar calidad y consistencia.

### DescripciÃ³n del Dataset

*   **Cantidad de Instancias:** Datos mensuales correspondientes a capturas, esfuerzo pesquero, temperatura superficial y regulaciÃ³n de veda.
*   **PerÃ­odo Cubierto:** Desde enero de 2019 hasta diciembre de 2024, totalizando 72 meses.
*   **Frecuencia:** Datos agrupados a nivel mensual por puerto (principalmente Punta Arenas).
*   **Total de Registros:** Aproximadamente 784 instancias, integrando mÃºltiples variables para anÃ¡lisis y modelado.

### CaracterÃ­sticas (Columnas) y Tipos de Datos

*   **AÃ±o:** AÃ±o de registro (tipo: entero).
*   **Mes:** Mes de registro (tipo: entero o texto abreviado).
*   **Especie:** Nombre comÃºn o cientÃ­fico de la especie (tipo: texto).
*   **Volumen de Captura (toneladas):** Cantidad de centolla desembarcada (tipo: float).
*   **Esfuerzo Pesquero (horas):** Horas de pesca reportadas en la zona (tipo: float).
*   **NÃºmero de Embarcaciones:** Cantidad de embarcaciones activas en la pesca (tipo: entero).
*   **Tipo de Arte:** MÃ©todo o equipo de pesca utilizado (tipo: texto).
*   **Temperatura Superficial del Mar (Â°C):** Temperatura promedio mensual registrada en la zona de pesca (tipo: float).
*   **Estado de Veda:** Indicador binario o categÃ³rico que seÃ±ala si hay veda vigente en el mes (tipo: booleano o texto).
*   **Variables adicionales:** Variables calculadas o derivadas para el anÃ¡lisis (tipo: varios).

### InformaciÃ³n Relevante Adicional

*   **Datos Preliminares:** Los datos se encuentran sujetos a posibles actualizaciones y correcciones posteriores a procesos de limpieza y validaciÃ³n.
*   **Valores Faltantes:** Existen registros con datos ausentes o nulos en algunas variables, particularmente en el esfuerzo pesquero y temperatura, que fueron tratados durante la limpieza.
*   **Consistencia:** Se aplicaron procesos de depuraciÃ³n para homogeneizar nombres de especies, formatos de fecha y codificaciÃ³n de variables categÃ³ricas.

---
---

## AnÃ¡lisis exploratorio de datos

Se realizaron anÃ¡lisis grÃ¡ficos y estadÃ­sticos, incluyendo:

- Captura total anual y promedio mensual de centolla.  
- RelaciÃ³n entre esfuerzo pesquero, temperatura y volumen capturado.  
- Impacto de la veda en los volÃºmenes de pesca.

![graficos](img/graficofin.png)

---

## Conclusiones del anÃ¡lisis exploratorio

â–“â–“â–“ ANÃLISIS EXPLORATORIO DE DATOS: CONCLUSIONES â–“â–“â–“
ğŸ”¬ AnÃ¡lisis Predictivo de Volumen de Captura | Lithodes santolla | Tierra del Fuego
bashâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 DATASET: Registro de Capturas Pesqueras  
 PERÃODO: 2020-2024 | REGIÃ“N: Punta Arenas
 ESTADO: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100% COMPLETADO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ MÃ“DULO 01 â†’ ANÃLISIS TEMPORAL: CAPTURA ANUAL
ğŸ“Š PATRÃ“N DETECTADO: Discontinuidad temporal significativa
python# AÃ±os de mÃ¡xima actividad pesquera
aÃ±os_pico = [2020, 2021]     # VolÃºmenes superiores al promedio base
brecha_datos = [2022, 2023]  # Ausencia de datos crÃ­ticos  
estado_actual = 2024         # Captura marginal detectada

âš ï¸ VARIABLES EXPLICATIVAS IDENTIFICADAS
diff+ Modificaciones en marco regulatorio pesquero
+ ExtensiÃ³n de perÃ­odos de veda biolÃ³gica
+ Fluctuaciones naturales en biomasa poblacional
! Inconsistencias en sistema de registro de datos
- Factores socio-econÃ³micos externos (COVID-19)


ğŸ¯ MÃ“DULO 02 â†’ ANÃLISIS ESTACIONAL: DISTRIBUCIÃ“N MENSUAL
ğŸ“ˆ PATRÃ“N DETECTADO: Estacionalidad pronunciada
sql-- Consulta de distribuciÃ³n estacional
SELECT mes, PROMEDIO(volumen_captura) 
FROM datos_pesca 
WHERE mes IN ('Octubre', 'Noviembre', 'Diciembre')
ORDER BY volumen_captura DESC;

-- RESULTADO: Noviembre > Diciembre > Octubre
ğŸ”¥ INSIGHT CLAVE: ConcentraciÃ³n en Q4
MESVOLUMEN RELATIVOSIGNIFICANCIANoviembreâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%PICO ABSOLUTODiciembreâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 85%ALTAOctubreâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 70%MODERADA
CORRELACIÃ“N IDENTIFICADA: SincronizaciÃ³n perfecta con ventanas regulatorias post-veda

ğŸ¯ MÃ“DULO 03 â†’ ANÃLISIS DE CORRELACIÃ“N: ESFUERZO vs RENDIMIENTO
âš¡ MODELO: AnÃ¡lisis de RelaciÃ³n Esfuerzo-Rendimiento
r# AnÃ¡lisis de correlaciÃ³n avanzado
coeficiente_correlacion <- cor(horas_pesca, volumen_captura)
modelo_regresion <- lm(volumen ~ esfuerzo + factores_ambientales)

# RÂ² moderado con alta dispersiÃ³n residual detectada
ğŸ“ HALLAZGOS ESTADÃSTICOS
yamlCORRELACIÃ“N_POSITIVA: 
  tendencia: "esfuerzo_mayor â†’ captura_mayor"
  intensidad: "moderada"
  
ALTA_VARIANZA:
  dispersiÃ³n: "significativa"
  outliers: "detectados"
  
CASOS_ATÃPICOS:
  - alto_esfuerzo_baja_captura: "identificados"
  - bajo_esfuerzo_alta_captura: "documentados"
ğŸ” FACTORES DE VARIABILIDAD IDENTIFICADOS
mermaidgraph TD
    A[Esfuerzo Pesquero] --> B{Volumen Capturado}
    C[Abundancia Espacial] --> B
    D[Condiciones OceanogrÃ¡ficas] --> B
    E[Eficiencia de Flota] --> B
    F[Factores EstocÃ¡sticos] --> B

ğŸ¯ MÃ“DULO 04 â†’ ANÃLISIS MULTIVARIADO: TEMPERATURA vs CAPTURA
ğŸŒ¡ï¸ RESULTADO: RelaciÃ³n estadÃ­sticamente no significativa
python# Test de significancia estadÃ­stica
import scipy.stats as stats

p_valor = stats.pearsonr(temperatura_superficial, volumen_captura)[1]
resultado = "No significativa" if p_valor > 0.05 else "Significativa"

# OUTPUT: p > 0.05 â†’ No rechazar Hâ‚€ (independencia)
ğŸ§® INTERPRETACIONES ALGORÃTMICAS
TIPODESCRIPCIÃ“NPROBABILIDADDIRECTATemperatura como predictor primarioBAJAINDIRECTAEfectos mediados por variables latentesALTATEMPORALEfectos con lag temporal no capturadosMEDIA

âš¡ SÃNTESIS EJECUTIVA: HALLAZGOS CLAVE
ğŸšï¸ RANKING DE IMPORTANCIA DE VARIABLES
cssâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    FEATURE IMPORTANCE                        â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Variable                 â”‚ Poder Pred. â”‚ Sig. Est. â”‚ Impacto â•‘
â•‘â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â•‘
â•‘ Estacionalidad Temporal  â”‚    ALTO     â”‚ p<0.001  â”‚ CRÃTICO â•‘
â•‘ Variabilidad Interanual  â”‚    ALTO     â”‚ p<0.01   â”‚   ALTO  â•‘  
â•‘ Esfuerzo Pesquero       â”‚   MEDIO     â”‚ p<0.05   â”‚  MEDIO  â•‘
â•‘ Temperatura Superficial â”‚    BAJO     â”‚ p>0.05   â”‚   BAJO  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸš€ PIPELINE DE RECOMENDACIONES ALGORÃTMICAS
ACCIONES INMEDIATAS
pythondef siguiente_pipeline_analisis():
    modelos_recomendados = [
        'regresion_multivariada()',
        'series_temporales_predictivas()', 
        'evaluacion_impacto_politicas()',
        'modelado_sostenibilidad()'
    ]
    return execute_pipeline(modelos_recomendados)
ANALÃTICA AVANZADA
bashâ”Œâ”€ FASE 1: ANÃLISIS CUANTITATIVO
â”‚  â”œâ”€â”€ RegresiÃ³n Multiple: CuantificaciÃ³n de relaciones
â”‚  â”œâ”€â”€ Modelos Predictivos: Algoritmos de forecasting
â”‚  â””â”€â”€ AnÃ¡lisis de Series: Patrones temporales complejos
â”‚
â”œâ”€ FASE 2: EVALUACIÃ“N DE IMPACTO  
â”‚  â”œâ”€â”€ Assessment Regulatorio: EvaluaciÃ³n cuantitativa
â”‚  â”œâ”€â”€ MÃ©tricas de Sostenibilidad: Indicadores KPI
â”‚  â””â”€â”€ AnÃ¡lisis de PolÃ­ticas: Impacto de regulaciones
â”‚
â””â”€ FASE 3: EXPANSIÃ“N DE VARIABLES
   â”œâ”€â”€ Factores Ambientales: Variables oceanogrÃ¡ficas
   â”œâ”€â”€ Datos SocioeconÃ³micos: Variables de mercado
   â””â”€â”€ Machine Learning: Algoritmos de predicciÃ³n avanzados

ğŸ¯ CONCLUSIÃ“N FINAL
diff+ PATRÃ“N ESTACIONAL: Robustez estadÃ­stica confirmada en Q4
+ VARIABILIDAD INTERANUAL: Alta significancia como driver principal  
+ FACTORES REGULATORIOS: Emergen como variables de control crÃ­ticas
- VARIABLES AMBIENTALES: Requieren anÃ¡lisis mÃ¡s profundo para causalidad
! GAPS DE DATOS: CrÃ­ticos para robustez del modelo (2022-2023)

ğŸ”„ NEXT ITERATION:
ImplementaciÃ³n de modelos predictivos avanzados para optimizaciÃ³n de estrategias de captura sostenible
STATUS: READY FOR ADVANCED MODELING â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%

Estos resultados sugieren que la captura de centolla en Punta Arenas tiene una marcada estacionalidad y una fuerte variabilidad interanual. El esfuerzo pesquero tiene cierta relaciÃ³n con el volumen capturado, pero otros factores (regulaciones, clima, dinÃ¡mica poblacional) probablemente tambiÃ©n juegan un papel relevante.
SerÃ¡ Ãºtil profundizar en anÃ¡lisis de regresiÃ³n o modelos predictivos para comprender mejor las relaciones entre las variables y evaluar el impacto de la veda y las regulaciones sobre la sostenibilidad de la pesquerÃ­a.

---

## Modelo de Aprendizaje AutomÃ¡tico

- Algoritmos utilizados: RegresiÃ³n Lineal y Random Forest Regressor.  
- Variables predictoras: Esfuerzo pesquero, temperatura, indicadores de veda, y datos temporales.  
- Se aplicaron tÃ©cnicas de limpieza, normalizaciÃ³n y validaciÃ³n cruzada para garantizar robustez.

---

## EvaluaciÃ³n del modelo

| MÃ©trica               | RegresiÃ³n Lineal | Random Forest |
|-----------------------|------------------|---------------|
| MAE (Error absoluto)   | 7.90             | 0.14          |
| MSE (Error cuadrÃ¡tico) | 102.44           | 0.18          |
| RÂ² (DeterminaciÃ³n)     | 0.11             | 1.00          |

*(Incluir grÃ¡ficos de predicciÃ³n vs real para ambos modelos)*

---

## InterpretaciÃ³n y conclusiones finales

- El modelo Random Forest mostrÃ³ un desempeÃ±o superior, capturando con precisiÃ³n la variabilidad en los datos.  
- El modelo puede servir como herramienta predictiva para apoyar la toma de decisiones en la gestiÃ³n pesquera.  
- Limitaciones incluyen la cantidad y calidad de datos, asÃ­ como posibles variables no consideradas.

---

## Recomendaciones

- Ampliar el dataset con mÃ¡s variables ambientales y biolÃ³gicas.  
- Probar otros modelos y tÃ©cnicas avanzadas de machine learning.  
- Implementar monitoreo continuo para actualizar el modelo periÃ³dicamente.

---

## Entregables en el repositorio

- Notebooks: ExploraciÃ³n, anÃ¡lisis, modelado y depuraciÃ³n.  
- Dataset procesado (`dataset_modelado_final.csv`).  
- GrÃ¡ficos y reportes generados.  
- Documentos descriptivos y presentaciÃ³n ejecutiva.

---

---
Project Organization
------------

    â”œâ”€â”€ LICENSE
    â”œâ”€â”€ Makefile           <- Makefile with commands like `make data` or `make train`
    â”œâ”€â”€ README.md          <- The top-level README for developers using this project.
    â”œâ”€â”€ data
    â”‚Â Â  â”œâ”€â”€ external       <- Data from third party sources.
    â”‚Â Â  â”œâ”€â”€ interim        <- Intermediate data that has been transformed.
    â”‚Â Â  â”œâ”€â”€ processed      <- The final, canonical data sets for modeling.
    â”‚Â Â  â””â”€â”€ raw            <- The original, immutable data dump.
    â”‚
    â”œâ”€â”€ docs               <- A default Sphinx project; see sphinx-doc.org for details
    â”‚
    â”œâ”€â”€ models             <- Trained and serialized models, model predictions, or model summaries
    â”‚
    â”œâ”€â”€ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
    â”‚                         the creator's initials, and a short `-` delimited description, e.g.
    â”‚                         `1.0-jqp-initial-data-exploration`.
    â”‚
    â”œâ”€â”€ references         <- Data dictionaries, manuals, and all other explanatory materials.
    â”‚
    â”œâ”€â”€ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
    â”‚Â Â  â””â”€â”€ figures        <- Generated graphics and figures to be used in reporting
    â”‚
    â”œâ”€â”€ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
    â”‚                         generated with `pip freeze > requirements.txt`
    â”‚
    â”œâ”€â”€ setup.py           <- makes project pip installable (pip install -e .) so src can be imported
    â”œâ”€â”€ src                <- Source code for use in this project.
    â”‚Â Â  â”œâ”€â”€ __init__.py    <- Makes src a Python module
    â”‚   â”‚
    â”‚Â Â  â”œâ”€â”€ data           <- Scripts to download or generate data
    â”‚Â Â  â”‚Â Â  â””â”€â”€ make_dataset.py
    â”‚   â”‚
    â”‚Â Â  â”œâ”€â”€ features       <- Scripts to turn raw data into features for modeling
    â”‚Â Â  â”‚Â Â  â””â”€â”€ build_features.py
    â”‚   â”‚
    â”‚Â Â  â”œâ”€â”€ models         <- Scripts to train models and then use trained models to make
    â”‚   â”‚   â”‚                 predictions
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ predict_model.py
    â”‚Â Â  â”‚Â Â  â””â”€â”€ train_model.py
    â”‚   â”‚
    â”‚Â Â  â””â”€â”€ visualization  <- Scripts to create exploratory and results oriented visualizations
    â”‚Â Â      â””â”€â”€ visualize.py
    â”‚
    â””â”€â”€ tox.ini            <- tox file with settings for running tox; see tox.readthedocs.io


--------